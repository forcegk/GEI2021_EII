@electronic{arm_aws_graviton_overview,
  title = {AWS Graviton overview by ARM},
  publisher = {Arm Ltd [GB]},
  url = {https://www.arm.com/why-arm/partner-ecosystem/aws},
  urldate = {2020-12-27}
}

@electronic{apple_m1_overview,
  title = {Apple M1 Chip Overview},
  publisher = {Apple Inc. [US]},
  year = {2020},
  url = {https://www.apple.com/mac/m1/},
  urldate = {2020-12-27}
}

@INPROCEEDINGS{risc_vs_cisc_6522302,
  author={E. {Blem} and J. {Menon} and K. {Sankaralingam}},
  booktitle={2013 IEEE 19th International Symposium on High Performance Computer Architecture (HPCA)}, 
  title={Power struggles: Revisiting the RISC vs. CISC debate on contemporary ARM and x86 architectures}, 
  year={2013},
  volume={},
  number={},
  pages={1-12},
  abstract={RISC vs. CISC wars raged in the 1980s when chip area and processor design complexity were the primary constraints and desktops and servers exclusively dominated the computing landscape. Today, energy and power are the primary design constraints and the computing landscape is significantly different: growth in tablets and smartphones running ARM (a RISC ISA) is surpassing that of desktops and laptops running x86 (a CISC ISA). Further, the traditionally low-power ARM ISA is entering the high-performance server market, while the traditionally high-performance x86 ISA is entering the mobile low-power device market. Thus, the question of whether ISA plays an intrinsic role in performance or energy efficiency is becoming important, and we seek to answer this question through a detailed measurement based study on real hardware running real applications. We analyze measurements on the ARM Cortex-A8 and Cortex-A9 and Intel Atom and Sandybridge i7 microprocessors over workloads spanning mobile, desktop, and server computing. Our methodical investigation demonstrates the role of ISA in modern microprocessors' performance and energy efficiency. We find that ARM and x86 processors are simply engineering design points optimized for different levels of performance, and there is nothing fundamentally more energy efficient in one ISA class or the other. The ISA being RISC or CISC seems irrelevant.},
  keywords={computational complexity;integrated circuit design;microprocessor chips;parallel architectures;reduced instruction set computing;RISC;CISC;ARM architectures;x86 architectures;chip area;processor design complexity;desktops;servers;design constraints;computing landscape;low-power ARM ISA;x86 ISA;ARM Cortex-A8;ARM Cortex-A9;Intel Atom microprocessors;Sandybridge i7 microprocessors;Abstracts;Reduced instruction set computing;Mobile communication;Servers},
  doi={10.1109/HPCA.2013.6522302},
  ISSN={1530-0897},
  month={Feb}
}

@inbook{measuring_moores_law_NBERc13897,
 Crossref = "NBERcorr-2",
 title = "Measuring Mooreâ€™s Law: Evidence from Price, Cost, and Quality Indexes",
 author = "Kenneth Flamm",
 BookTitle = "Measuring and Accounting for Innovation in the Twenty-First Century",
 Publisher = "University of Chicago Press",
 year = "2019",
 month = "May",
 URL = "http://www.nber.org/chapters/c13897",
}

@inproceedings{inside_netburst_architecture_carmean2000inside,
  title={Inside the pentium 4 processor microarchitecture},
  author={Carmean, Doug},
  booktitle={Intel Developer Forum},
  year={2000},
  URL = "https://courses.cs.washington.edu/courses/cse548/05wi/files/Pentium4-Microarchitecture-Slides.pdf"
}

@electronic{ampere_announces_128_core_arm_server_cpu,
  title = {Ampere announces 128-core Arm server processor},
  publisher = {networkworld.com},
  date = {2020-06-29},
  url = {https://www.networkworld.com/article/3564514/ampere-announces-128-core-arm-server-processor.html},
  urldate = {2021-01-12}
}

@article{datacenter_energy_cost_SONG20151255,
title = "Data Center Energy and Cost Saving Evaluation",
journal = "Energy Procedia",
volume = "75",
pages = "1255 - 1260",
year = "2015",
note = "Clean, Efficient and Affordable Energy for a Sustainable Future: The 7th International Conference on Applied Energy (ICAE2015)",
issn = "1876-6102",
doi = "https://doi.org/10.1016/j.egypro.2015.07.178",
url = "http://www.sciencedirect.com/science/article/pii/S1876610215009467",
author = "Z. Song and X. Zhang and C. Eriksson",
keywords = "Data center, Cooling, Energy efficiency",
abstract = "In data centers, about 40\% of the total energy is consumed for cooling the IT equipment. Cooling costs are thus one of the major contributors to the total electricity bill of large data centers. This paper studies two factors affecting data center cooling energy consumption, namely air flow management and data center location selection. A unique rack layout with a vertically cooling air flow is proposed. Two cooling systems, computer room air conditioning (CRAC) cooling system and airside economizer (ASE), have been studied. Based on these two cooling systems, four cities have been selected from the worldwide data center locations. A number of energy efficiency metrics are explored for data center cooling, such as power usage effectiveness (PUE), coefficient of performance (COP) and chiller hours. By analyzing the effects of chiller hours and economizer hours, comparative economic results of cooling power consumption are provided in both systems. The results show that the cooling efficiency and operating costs vary significantly with different climate conditions, energy prices and cooling technologies. As climate condition is the major factor which affects the airside economizer, employing the airside economizer in the cold climate yields much lower energy consumption and operation costs."
}

@techreport {usa_datacenter_energy_usage_report_61109,
	title = {United States Data Center Energy Usage Report},
	year = {2016},
	month = {06/2016},
	abstract = {<p>This report estimates historical data center electricity consumption back to 2000, relying on previous studies and historical shipment data, and forecasts consumption out to 2020 based on new trends and the most recent data available. Figure ES-1 provides an estimate of total U.S. data center electricity use (servers, storage, network equipment, and infrastructure) from 2000-2020. In 2014, data centers in the U.S. consumed an estimated 70 billion kWh, representing about 1.8\% of total U.S. electricity consumption. Current study results show data center electricity consumption increased by about 4\% from 2010-2014, a large shift from the 24\% percent increase estimated from 2005-2010 and the nearly 90\% increase estimated from 2000- 2005. Energy use is expected to continue slightly increasing in the near future, increasing 4\% from 2014-2020, the same rate as the past five years. Based on current trend estimates, U.S. data centers are projected to consume approximately 73 billion kWh in 2020.</p>

<p>Many factors contribute to the overall energy trends found in this report, though the most conspicuous change may be the reduced growth in the number of servers operating in data centers. While shipments of new servers into data centers continue to grow every year, the growth rate has diminished over the past 15 years. From 2000-2005, server shipments increased by 15\% each year resulting in a near doubling of servers operating in data centers. From 2005-2010, the annual shipment increase fell to 5\%, partially driven by a conspicuous drop in 2009 shipments (most likely from the economic recession), as well as from the emergence of server virtualization across that 5-year period. The annual growth in server shipments further dropped after 2010 to 3\% and that growth rate is now expected to continue through 2020. This 3\% annual growth rate coincides with the rise in very large "hyperscale" data centers and an increased popularity of moving previously localized data center activity to colocation or cloud facilities. In fact, nearly all server shipment growth since 2010 occurred in servers destined for large hyperscale data centers, where servers are often configured for maximum productivity and operated at high utilization rates, resulting in fewer servers needed in the hyperscale data centers than would be required to provide the same services in traditional, smaller, data centers.</p>

<p>Along with total server count, the power demand for each server has also changed. While server power requirements were observed to be increasing from 2000-2005, power demand appears to have stayed fairly constant since 2005. Additionally, servers are improving in their power scaling abilities, thus reducing power draw during idle periods or when at low utilization. Efficiency improvements in storage, network and infrastructure also influence the electricity estimates in this report. Storage devices are becoming more efficient on a per-drive basis, with the growth in drive storage capacity projected to outpace increases in data storage demand by 2020, ultimately reducing the number of physical drives needed throughout data centers. Recent estimates of network port power consumption are now much lower than estimates from the past decade. Increased awareness in data center infrastructure operations (e.g. cooling) has resulted in improved efficiency across data center types, though the most significant infrastructure impact observed in this report is the recent growth in hyperscale data centers that are often innovatively designed to maximum infrastructure efficiency.</p>

<p>The combination of these efficiency trends has resulted in a relatively steady U.S data center electricity demand over the past 5 years, with little growth expected for the remainder of this decade. It is important to note that this near constant electricity demand across the decade is occurring while simultaneously meeting a drastic increase in demand for data center services; data center electricity use would be significantly higher without these energy efficiency improvements. A counterfactual scenario was created for this study that estimates what data center energy consumption would have been if industry energy-savings efforts were halted in 2010. For this scenario, the follow metrics remain static at 2010 industry-wide levels from 2010-2020:</p>

<ul>
	<li>Average server utilization</li>

	<li>Server power scaling at low utilization</li>

	<li>Average power draw of hard disk drives</li>

	<li>Average power draw of network ports</li>

	<li>Average infrastructure efficiency (i.e., PUE)</li>
</ul>

<p>Note that this scenario does not halt the technological advancements of the computing industry in terms of performance, and therefore metrics such as computational performance (i.e., computations/second per server), the electrical efficiency of computations (i.e., computations per kWh), storage capacity (i.e., TB per drive), and port speeds (i.e., Gb per port) are all assumed to progress as normal. See Section 2.3.5 in the main body of this report for more details regarding the assumptions in this counterfactual scenario.</p>

<p>Along with the considerable energy efficiency resource already achieved, there are additional energy efficiency strategies and technologies that could significantly reduce data center electricity use below the approximately 73 billion kWh demand projected in 2020. Many of these efficiency strategies are already successfully employed in some data centers while others are emerging technologies that will be commercially available in the near future. Recently observed efficiency trends are incorporated into a "current trends" scenario. The potential impact from a more aggressive adoption of the energy efficiency strategies is explored through additional projections that apply a combination of the three following efficiency scenarios:</p>

<ul>
	<li>The "improved management" scenario includes energy-efficiency improvements beyond current trends that are either operational or technological changes that require minimal capital investment. This scenario represents a focus on improving the least efficient components of the data center stock by employing practices already commonly used in data centers.</li>

	<li>The "best practices" scenario represents the efficiency gains that can be obtained through the widespread adoption the most efficient technologies and best management practices applicable to each data center type. This scenario focuses on maximizing the efficiency of each type of data center facility.</li>

	<li>The "hyperscale shift" scenario represents an aggressive shift of data center activity from smaller data centers to larger data centers. While the current trend scenario already incorporates some movement towards more server use in large data centers, this scenario assumes the majority of servers in the remaining small data centers are also relocated.</li>
</ul>

<p>In addition to applying each of these scenarios independently, two additional scenarios demonstrate the combination of a "hyperscale shift" scenario in conjunction with either the "improved operation" or "best practices" scenario. Figure ES-1 shows that these five scenarios yield an annual saving in 2020 up to 33 billion kWh, representing a 45\% reduction in electricity demand when compared to current efficiency trends.</p>
},
	keywords = {data center, energy efficiency, information technology},
	author = {Arman Shehabi and Sarah Josephine Smith and Dale A. Sartor and Richard E. Brown and Magnus Herrlin and Jonathan G. Koomey and Eric R. Masanet and Horner, Nathaniel and In{\^e}s Lima Azevedo and Lintner, William}
}

@electronic{graviton2_vs_amd_vs_intel_cloud_compute,
  title = {Amazon's Arm-based Graviton2 Against AMD and Intel: Comparing Cloud Compute},
  publisher = {AnandTech},
  date = {2020-03-10},
  url = {https://www.anandtech.com/show/15578/cloud-clash-amazon-graviton2-arm-against-intel-and-amd/5},
  urldate = {2021-01-13}
}

@electronic{graviton1_graviton2_zdnet_aws,
  title = {AWS Graviton2: What it means for Arm in the data center, cloud, enterprise, AWS},
  publisher = {ZDNet},
  date = {2019-12-03},
  url = {https://www.zdnet.com/article/aws-graviton2-what-it-means-for-arm-in-the-data-center-cloud-enterprise-aws/},
  urldate = {2021-01-15}
}
